"""
Agentå·¥ä½œæµå®ç°
"""

from typing import List, Dict, Literal
from langgraph.graph import StateGraph, END
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
import json

from core.agents import AgentState, AgentType
from core.system_prompts import (
    ECHO_SYSTEM_PROMPT,
    ELON_SYSTEM_PROMPT,
    HENRY_SYSTEM_PROMPT
)

# åˆ›å»ºLLMå®ä¾‹
def get_llm(agent_type: str):
    """è·å–å¯¹åº”Agentçš„LLMå®ä¾‹"""
    if agent_type in [AgentType.ELON, AgentType.ARCHITECT, AgentType.CODER, AgentType.QA]:
        return ChatOpenAI(model="gpt-4", temperature=0.2)
    else:
        return ChatAnthropic(
            model="claude-sonnet-4-20250514",
            temperature=0.3
        )

# Echoå·¥ä½œæµ
def create_echo_workflow():
    """åˆ›å»ºEchoå·¥ä½œæµ"""

    def parse_intention(state: AgentState):
        """è§£æç”¨æˆ·æ„å›¾"""
        llm = get_llm(AgentType.ECHO)

        prompt = f"""ä½œä¸ºEchoï¼Œè¯·è§£æä»¥ä¸‹ç”¨æˆ·æ„å›¾å¹¶æ‹†è§£ä»»åŠ¡ï¼š

ç”¨æˆ·æ¶ˆæ¯ï¼š{state['task']}

è¯·æ‹†è§£ä¸ºï¼š
1. Tech_Task: æŠ€æœ¯ä»»åŠ¡ï¼ˆéœ€è¦Elonæ‰§è¡Œï¼‰
2. Market_Task: å¸‚åœºä»»åŠ¡ï¼ˆéœ€è¦Henryæ‰§è¡Œï¼‰

æ ¼å¼ï¼š
Tech_Task: [æè¿°æŠ€æœ¯ä»»åŠ¡]
Market_Task: [æè¿°å¸‚åœºä»»åŠ¡]"""

        response = llm.invoke(prompt)
        content = response.content

        # è§£æå“åº”
        tech_task = None
        market_task = None

        lines = content.split('\n')
        for line in lines:
            if 'Tech_Task:' in line:
                tech_task = line.replace('Tech_Task:', '').strip()
            elif 'Market_Task:' in line:
                market_task = line.replace('Market_Task:', '').strip()

        return {
            **state,
            'tech_tasks': [{'type': 'tech', 'description': tech_task}] if tech_task else [],
            'market_tasks': [{'type': 'market', 'description': market_task}] if market_task else []
        }

    def dispatch_tasks(state: AgentState):
        """åˆ†å‘ä»»åŠ¡"""
        return {
            **state,
            'current_agent': 'dispatching',
            'messages': state['messages'] + ['ä»»åŠ¡å·²åˆ†å‘ï¼Œæ­£åœ¨æ‰§è¡Œ...']
        }

    def monitor_progress(state: AgentState):
        """ç›‘æ§è¿›åº¦"""
        return {
            **state,
            'current_agent': 'monitoring',
            'status': 'thinking'
        }

    def generate_report(state: AgentState):
        """ç”ŸæˆæŠ¥å‘Š"""
        report = f"""âœ… ä»»åŠ¡æ‰§è¡Œå®ŒæˆæŠ¥å‘Š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š æ‰§è¡ŒçŠ¶æ€ï¼šå®Œæˆ
â±ï¸  è€—æ—¶ï¼š{state.get('duration', 'æœªçŸ¥')}ç§’

ğŸ“‹ ä»»åŠ¡æ¦‚è§ˆï¼š
"""

        if state.get('tech_tasks'):
            report += "ğŸ”§ æŠ€æœ¯ä»»åŠ¡ï¼š\n"
            for task in state['tech_tasks']:
                report += f"  - {task['description']}\n"

        if state.get('market_tasks'):
            report += "ğŸ“¢ å¸‚åœºä»»åŠ¡ï¼š\n"
            for task in state['market_tasks']:
                report += f"  - {task['description']}\n"

        if state.get('elon_output'):
            report += f"\nğŸ’» æŠ€æœ¯äº§å‡ºï¼š\n{state['elon_output']}\n"

        if state.get('henry_output'):
            report += f"\nğŸ“¢ å¸‚åœºäº§å‡ºï¼š\n{state['henry_output']}\n"

        report += f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n
æ„Ÿè°¢ä½¿ç”¨Hive Mindï¼"""

        return {
            **state,
            'progress_report': report,
            'status': 'idle',
            'current_agent': 'echo'
        }

    # åˆ›å»ºå›¾
    graph = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("parse_intention", parse_intention)
    graph.add_node("dispatch_tasks", dispatch_tasks)
    graph.add_node("monitor_progress", monitor_progress)
    graph.add_node("generate_report", generate_report)

    # æ·»åŠ è¾¹
    graph.set_entry_point("parse_intention")
    graph.add_edge("parse_intention", "dispatch_tasks")
    graph.add_edge("dispatch_tasks", "monitor_progress")
    graph.add_edge("monitor_progress", "generate_report")
    graph.add_edge("generate_report", END)

    return graph.compile()

# Elonå·¥ä½œæµ
def create_elon_workflow():
    """åˆ›å»ºElonå·¥ä½œæµ"""

    def architect_design(state: AgentState):
        """æ¶æ„è®¾è®¡"""
        llm = get_llm(AgentType.ARCHITECT)

        prompt = f"""ä½œä¸ºElonçš„Architectï¼Œè¯·ä¸ºä»¥ä¸‹ä»»åŠ¡è®¾è®¡æŠ€æœ¯æ–¹æ¡ˆï¼š

ä»»åŠ¡ï¼š{state['task']}

è¯·æä¾›ï¼š
1. æŠ€æœ¯æ ˆé€‰å‹
2. æ¨¡å—æ¶æ„è®¾è®¡
3. APIå®šä¹‰
4. æ•°æ®åº“è®¾è®¡

æ ¼å¼ï¼š
**æŠ€æœ¯æ ˆï¼š**
- è¯­è¨€/æ¡†æ¶
- æ•°æ®åº“
- å…¶ä»–

**æ¶æ„è®¾è®¡ï¼š**
[è¯¦ç»†æè¿°]

**APIå®šä¹‰ï¼š**
[æ¥å£åˆ—è¡¨]"""

        response = llm.invoke(prompt)
        return {
            **state,
            'architecture': json.loads(response.content) if '```json' in response.content else {},
            'elon_output': response.content,
            'progress': 30
        }

    def coder_execute(state: AgentState):
        """ä»£ç æ‰§è¡Œ"""
        llm = get_llm(AgentType.CODER)

        prompt = f"""ä½œä¸ºElonçš„Coderï¼Œè¯·å®ç°ä»¥ä¸‹æ¶æ„è®¾è®¡ï¼š

ä»»åŠ¡ï¼š{state['task']}
æ¶æ„ï¼š{json.dumps(state.get('architecture', {}), ensure_ascii=False, indent=2)}

è¯·æä¾›å®Œæ•´çš„ä»£ç å®ç°"""

        response = llm.invoke(prompt)
        return {
            **state,
            'code': response.content,
            'elon_output': response.content,
            'progress': 60
        }

    def qa_test(state: AgentState):
        """æµ‹è¯•"""
        llm = get_llm(AgentType.QA)

        prompt = f"""ä½œä¸ºElonçš„QAï¼Œè¯·å¯¹ä»¥ä¸‹ä»£ç è¿›è¡Œæµ‹è¯•ï¼š

ä»£ç ï¼š
{state.get('code', '')}

è¯·æä¾›ï¼š
1. å•å…ƒæµ‹è¯•ä»£ç 
2. æµ‹è¯•ç”¨ä¾‹
3. é¢„æœŸç»“æœ"""

        response = llm.invoke(prompt)
        return {
            **state,
            'tests': response.content,
            'progress': 80
        }

    def reviewer_check(state: AgentState):
        """ä»£ç å®¡æŸ¥"""
        llm = get_llm(AgentType.REVIEWER)

        prompt = f"""ä½œä¸ºElonçš„Reviewerï¼Œè¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç ï¼š

ä»£ç ï¼š
{state.get('code', '')}

æµ‹è¯•ï¼š
{state.get('tests', '')}

è¯·æä¾›å®¡æŸ¥æ„è§å’Œæ”¹è¿›å»ºè®®"""

        response = llm.invoke(prompt)
        return {
            **state,
            'review': response.content,
            'progress': 100
        }

    # åˆ›å»ºå›¾
    graph = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("architect_design", architect_design)
    graph.add_node("coder_execute", coder_execute)
    graph.add_node("qa_test", qa_test)
    graph.add_node("reviewer_check", reviewer_check)

    # æ·»åŠ è¾¹
    graph.set_entry_point("architect_design")
    graph.add_edge("architect_design", "coder_execute")
    graph.add_edge("coder_execute", "qa_test")
    graph.add_edge("qa_test", "reviewer_check")
    graph.add_edge("reviewer_check", END)

    return graph.compile()

# Henryå·¥ä½œæµ
def create_henry_workflow():
    """åˆ›å»ºHenryå·¥ä½œæµ"""

    def researcher_scan(state: AgentState):
        """ç¤¾åŒºè°ƒç ”"""
        llm = get_llm(AgentType.RESEARCHER)

        prompt = f"""ä½œä¸ºHenryçš„Researcherï¼Œè¯·è°ƒç ”ä»¥ä¸‹ä¿¡æ¯ï¼š

ä»»åŠ¡ï¼š{state['task']}

è¯·æä¾›ï¼š
1. ç›¸å…³çš„å¼€æºé¡¹ç›®
2. ç¤¾åŒºè®¨è®ºçƒ­ç‚¹
3. ç±»ä¼¼åŠŸèƒ½çš„å®ç°æ–¹æ¡ˆ
4. å¸‚åœºæœºä¼š"""

        response = llm.invoke(prompt)
        return {
            **state,
            'research': response.content,
            'henry_output': response.content,
            'progress': 30
        }

    def writer_create(state: AgentState):
        """å†…å®¹åˆ›ä½œ"""
        llm = get_llm(AgentType.WRITER)

        prompt = f"""ä½œä¸ºHenryçš„Writerï¼Œè¯·æ ¹æ®ä»¥ä¸‹è°ƒç ”ç»“æœåˆ›å»ºå†…å®¹ï¼š

è°ƒç ”ç»“æœï¼š
{state.get('research', '')}

ä»»åŠ¡ï¼š{state['task']}

è¯·æä¾›ï¼š
1. PRæè¿°
2. Release Notes
3. ç¤¾åŒºæ¨æ–‡
4. åšå®¢æ–‡ç« 

æ ¼å¼ï¼š
**PRæè¿°ï¼š**
[å†…å®¹]

**Release Notesï¼š**
[å†…å®¹]

**ç¤¾åŒºæ¨æ–‡ï¼š**
[å†…å®¹]

**åšå®¢æ–‡ç« ï¼š**
[å†…å®¹]"""

        response = llm.invoke(prompt)
        return {
            **state,
            'content': response.content,
            'henry_output': response.content,
            'progress': 60
        }

    def networker_interact(state: AgentState):
        """ç¤¾äº¤äº’åŠ¨"""
        llm = get_llm(AgentType.NETWORKER)

        prompt = f"""ä½œä¸ºHenryçš„Networkerï¼Œè¯·å‡†å¤‡ç¤¾äº¤äº’åŠ¨å†…å®¹ï¼š

ä»»åŠ¡ï¼š{state['task']}
å†…å®¹ï¼š{state.get('content', '')}

è¯·æä¾›ï¼š
1. ç¤¾åŒºäº’åŠ¨ç­–ç•¥
2. å›å¤æ¨¡æ¿
3. @æåŠå»ºè®®
4. æ³¨æ„äº‹é¡¹"""

        response = llm.invoke(prompt)
        return {
            **state,
            'networking': response.content,
            'progress': 100
        }

    # åˆ›å»ºå›¾
    graph = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    graph.add_node("researcher_scan", researcher_scan)
    graph.add_node("writer_create", writer_create)
    graph.add_node("networker_interact", networker_interact)

    # æ·»åŠ è¾¹
    graph.set_entry_point("researcher_scan")
    graph.add_edge("researcher_scan", "writer_create")
    graph.add_edge("writer_create", "networker_interact")
    graph.add_edge("networker_interact", END)

    return graph.compile()

# ç¼–è¯‘æ‰€æœ‰å·¥ä½œæµ
ECHO_WORKFLOW = create_echo_workflow()
ELON_WORKFLOW = create_elon_workflow()
HENRY_WORKFLOW = create_henry_workflow()
